***************************************************************************************************** 
* WARNING: The 2021 software stack is not available on the 'genoa' partition.
Please use the 2022 * 
* software stack. * 
* * 
* If you have any question, please contact us via
http://servicedesk.surfsara.nl. * 
***************************************************************************************************** 
/gpfs/home4/dfruhbus/Lama/transformers/src/transformers/models/auto/tokenization_auto.py:628: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/gpfs/home4/dfruhbus/Lama/transformers/src/transformers/models/auto/auto_factory.py:460: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   7%|▋         | 1/15 [00:03<00:55,  3.99s/it]Loading checkpoint shards:  13%|█▎        | 2/15 [00:07<00:51,  3.95s/it]Loading checkpoint shards:  20%|██        | 3/15 [00:11<00:47,  3.99s/it]Loading checkpoint shards:  27%|██▋       | 4/15 [00:15<00:43,  3.99s/it]Loading checkpoint shards:  33%|███▎      | 5/15 [00:20<00:40,  4.03s/it]Loading checkpoint shards:  40%|████      | 6/15 [00:24<00:36,  4.02s/it]Loading checkpoint shards:  47%|████▋     | 7/15 [00:27<00:31,  3.96s/it]Loading checkpoint shards:  53%|█████▎    | 8/15 [00:31<00:27,  3.97s/it]Loading checkpoint shards:  60%|██████    | 9/15 [00:35<00:23,  3.98s/it]Loading checkpoint shards:  67%|██████▋   | 10/15 [00:39<00:19,  3.98s/it]Loading checkpoint shards:  73%|███████▎  | 11/15 [00:43<00:16,  4.02s/it]Loading checkpoint shards:  80%|████████  | 12/15 [00:47<00:12,  4.01s/it]Loading checkpoint shards:  87%|████████▋ | 13/15 [00:51<00:07,  3.95s/it]Loading checkpoint shards:  93%|█████████▎| 14/15 [00:57<00:04,  4.42s/it]Loading checkpoint shards: 100%|██████████| 15/15 [00:57<00:00,  3.20s/it]Loading checkpoint shards: 100%|██████████| 15/15 [00:57<00:00,  3.84s/it]
/gpfs/home4/dfruhbus/Lama/transformers/src/transformers/utils/hub.py:372: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
LlamaForCausalLM(
  (model): LlamaModel(
    (embed_tokens): Embedding(32000, 8192)
    (layers): ModuleList(
      (0-79): 80 x LlamaDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=8192, out_features=8192, bias=False)
          (k_proj): Linear(in_features=8192, out_features=1024, bias=False)
          (v_proj): Linear(in_features=8192, out_features=1024, bias=False)
          (o_proj): Linear(in_features=8192, out_features=8192, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LlamaMLP(
          (gate_proj): Linear(in_features=8192, out_features=28672, bias=False)
          (up_proj): Linear(in_features=8192, out_features=28672, bias=False)
          (down_proj): Linear(in_features=28672, out_features=8192, bias=False)
          (act_fn): SiLUActivation()
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=8192, out_features=32000, bias=False)
)

JOB STATISTICS
==============
Job ID: 3901451
Cluster: snellius
User/Group: dfruhbus/dfruhbus
State: RUNNING
Nodes: 1
Cores per node: 36
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 05:30:36 core-walltime
Job Wall-clock time: 00:09:11
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 480.00 GB (480.00 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
